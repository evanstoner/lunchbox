---
# create an empty project as a placeholder
kind: Project
apiVersion: project.openshift.io/v1
metadata:
  name: demo
---
# add gitops user to demo project
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: gitops-manage-demo
  namespace: demo
subjects:
  - kind: ServiceAccount
    name: openshift-gitops-argocd-application-controller
    namespace: openshift-gitops
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: admin
---
# create a demo VM, so we have a place to run demos inside the cluster. this is
# especially important for those of us with an ARM chip, since the cluster is x86
# and we won't be able to use locally-built containers on the cluster
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  labels:
    app: rhel9-demo
  name: rhel9-demo
  namespace: demo
spec:
  dataVolumeTemplates:
    - apiVersion: cdi.kubevirt.io/v1beta1
      kind: DataVolume
      metadata:
        name: rhel9-demo
      spec:
        sourceRef:
          kind: DataSource
          name: rhel9
          namespace: openshift-virtualization-os-images
        storage:
          resources:
            requests:
              storage: 30Gi
  running: true
  template:
    metadata:
      labels:
        kubevirt.io/domain: rhel9-demo
    spec:
      domain:
        cpu:
          cores: 2
          sockets: 1
          threads: 1
        devices:
          disks:
            - disk:
                bus: virtio
              name: rootdisk
            - disk:
                bus: virtio
              name: cloudinitdisk
          interfaces:
            - masquerade: {}
              name: default
          rng: {}
        features:
          acpi: {}
          smm:
            enabled: true
        firmware:
          bootloader:
            efi: {}
        resources:
          requests:
            memory: 2Gi
      networks:
        - name: default
          pod: {}
      terminationGracePeriodSeconds: 180
      volumes:
        - dataVolume:
            name: rhel9-demo
          name: rootdisk
        - cloudInitNoCloud:
            userData: |-
              #cloud-config
              user: cloud-user
              password: shadowman
              chpasswd: { expire: False }
              runcmd:
              - systemctl enable cockpit.socket --now
          name: cloudinitdisk
---
# expose the VM's cockpit port so that we can make an external route next
kind: Service
apiVersion: v1
metadata:
  name: rhel9-demo
  namespace: demo
spec:
  type: ClusterIP
  selector:
    vm.kubevirt.io/name: rhel9-demo
  ports:
    - name: cockpit
      protocol: TCP
      port: 9090
      targetPort: 9090
---
# make cockpit externally accessible
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: rhel9-demo-cockpit
  namespace: demo
spec:
  host: rhel9-demo-cockpit.apps.sno.demo.local
  to:
    kind: Service
    name: rhel9-demo
    weight: 100
  port:
    targetPort: 9090
  tls:
    termination: passthrough
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None
